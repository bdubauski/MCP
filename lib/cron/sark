#!/usr/bin/env python3
#
#  sark
#
#   Checkes QueuItems to see if their resources are aviable, if they are, creates a buildjob and assigns resources
#   runs the Jobs through, when job complets calls signalComplete on the attached Commit or Promotion

import os

os.environ.setdefault( 'DJANGO_SETTINGS_MODULE', 'mcp.settings' )

import django
django.setup()

import sys
import logging
from logging.handlers import SysLogHandler
from datetime import datetime, timezone, timedelta

from mcp.Processor.models import QueueItem, BuildJob
from mcp.Resource.models import Network
from mcp.lib.Slack import getSlack

# in Hours
CLEANUP_DELAY = 0.2
AUTO_ACKNOLEDGE_DELAY = 24.0

PID_FILE = '/var/run/sark.pid'

logging.basicConfig()
logger = logging.getLogger()
handler = SysLogHandler( address='/dev/log', facility=SysLogHandler.LOG_DAEMON )
handler.setFormatter( logging.Formatter( fmt='sark[%(process)d]: %(message)s' ) )
logger.addHandler( handler )
if '-v' in sys.argv:
  logger.setLevel( logging.DEBUG )
elif '-c' in sys.argv:
  logger.setLevel( logging.ERROR )
else:
  logger.setLevel( logging.INFO )

if os.path.exists( PID_FILE ):
  logging.error( 'pid file exists, bailing...' )
  sys.exit( 0 )

tmp = open( PID_FILE, 'w' )
tmp.write( '{0}\n'.format( os.getpid() ) )
tmp.close()

slack = getSlack( 'sark' )


# Iterate over the Queued Items
for item in QueueItem.objects.all().order_by( '-priority' ):  # start with the biggest number first
  try:
    # Build a job
    job = BuildJob()
    job.manual = item.manual
    job.user = item.user
    job.build = item.build
    job.project = item.project
    job.branch = item.branch
    if item.branch == item.project.release_branch:
      job.build_name = str( item.project.build_counter )
    else:
      job.build_name = '{0}-{1}'.format( item.project.build_counter, item.branch )
    job.target = item.target
    job.commit = item.commit
    job.promotion = item.promotion

    ( missing_list, buildresource_list, network_map ) = item.allocateResources()
    if missing_list:
      logging.info( 'Queue Item "{0}" waiting for "{1}"'.format( item, missing_list ) )
      item.resource_status_map = { 'resource': missing_list }
      item.full_clean()
      item.save()
      continue

    job.full_clean()
    job.save()

    job.network_list = Network.objects.filter( name__in=network_map.keys() )

    for buildresource in buildresource_list:
      quanity = buildresource.quanity
      resource = buildresource.resource.subclass
      interface_map = buildresource.interface_map
      for name in interface_map.keys():
        interface_map[ name ][ 'network' ] = network_map[ interface_map[ name ].get( 'network', '_OTHER_' ) ]

      resource.allocate( job, buildresource.name, buildresource.quanity, interface_map )

    job.buildResources()
    logging.info( 'Starting Queue Item "{0}" as job "{1}"'.format( item, job.id ) )

    # remove the queue Item
    slack.post_message( 'Job {0} ( project: "{1}", build: "{2}", branch: "{3}", target: "{4}" ) for Queue Item {5} submitted.'.format( job.id, job.project.name, job.build.name, job.branch, job.target, item.id ), slack.INFO )
    item.delete()

  except Exception as e:
    logging.exception( 'Exception "{0}" creating job for queue item "{1}", skiping...'.format( e, item.pk ) )
    try:
      job.release()
    except Exception as e2:
      logging.exception( 'Exception "{0}" releaseing while skipping, probably creating a big mess...'.format( e2, item.pk ) )
      slack.post_message( '!!! Error releasing when there was an Exception allocating, I am probably making a mess !!!', slack.CRITICAL )

    item.resource_status_map = { 'error': 'Exception: "{0}"'.format( e ) }
    item.full_clean()
    item.save()


# Iterate over the build new jobs
for job in BuildJob.objects.filter( built_at__isnull=True, ran_at__isnull=True, reported_at__isnull=True, released_at__isnull=True ):
  # all done, set to built
  if job.instances_built:
    logging.info( 'Setting job "{0}" to Built.'.format( job.id ) )
    job.built_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()


# Iterate over the built jobs and see if all the instances are done, if so, flag as ran
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=True, reported_at__isnull=True, released_at__isnull=True ):
  # all done, set to ran
  if job.instances_ran:
    logging.info( 'Setting job "{0}" to Ran.'.format( job.id ) )
    job.ran_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()


# Iterate over the Ran jobs
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=True, released_at__isnull=True ):
  if job.commit is not None:
    job.commit.signalComplete( job.target, job.build.name, job.suceeded )

  elif job.promotion is not None:
    job.promotion.signalComplete( job.build, job.suceeded )

  else:
    logging.info( 'Job has nothing to report to, hopfully that was intentional' )

  commit = job.commit
  if commit is not None:
    commit.package_file_map.update( job.package_file_map )
    commit.full_clean()
    commit.save()

  logging.info( 'Setting job "{0}" to Reported.'.format( job.id ) )
  job.reported_at = datetime.now( timezone.utc )
  job.full_clean()
  job.save()

  results = ''
  for instance in job.instance_set.all().order_by( 'name' ):
    results += 'Instance: *{0}*\n'.format( instance )
    try:
      results += 'Success: *{0}*\n'.format( instance.success )
    except KeyError:
      pass

  slack.post_message( 'Job {0} ( project: "{1}", build: "{2}", branch: "{3}", target: "{4}" ) Completed.\n{5}'.format( job.id, job.project.name, job.build.name, job.branch, job.target, results ), slack.INFO )


# iterate over the Reported jobs that are not manual and look to see if the resources are all released
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, acknowledged_at__isnull=True, released_at__isnull=True, manual=False ):
  if job.suceeded:  # success auto Acknoledges
    job.acknowledged_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()
    continue

  # auto acknoledge after AUTO_ACKNOLEDGE_DELAY
  if job.reported_at < ( datetime.now( timezone.utc ) - timedelta( hours=AUTO_ACKNOLEDGE_DELAY ) ):
    job.acknowledged_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()
    continue


# iterate over the Acknoledged jobs, and release the resources
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, acknowledged_at__isnull=False, released_at__isnull=True ):
  job.release()

  # resources all released, set job to released
  if job.instances_released:
    logging.info( 'Setting job "{0}" to Released.'.format( job.id ) )
    job.released_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()


# Iterate over released jobs that are at least CLEANUP_DELAY hours old and delete them
for job in BuildJob.objects.filter( released_at__lt=( datetime.now( timezone.utc ) - timedelta( hours=CLEANUP_DELAY ) ) ):
  logging.info( 'Cleaning up job "{0}".'.format( job.id ) )
  for instance in job.instance_set.all():
    instance.delete()

  job.delete()


os.unlink( PID_FILE )
logging.info( 'Done!' )
logging.shutdown()
sys.exit( 0 )
