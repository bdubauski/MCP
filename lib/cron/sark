#!/usr/bin/env python3
#
#  sark
#
#   Checkes QueuItems to see if their resources are aviable, if they are, creates a buildjob and assigns resources
#   runs the Jobs through, when job complets calls signalComplete on the attached Commit or Promotion

import os

os.environ.setdefault( 'DJANGO_SETTINGS_MODULE', 'mcp.settings' )

import django
django.setup()

import sys
import logging
from logging.handlers import SysLogHandler
from datetime import datetime, timezone, timedelta

from django.conf import settings

from mcp.Processor.models import QueueItem, BuildJob
from mcp.lib.Slack import Slack

# in Hours
CLEANUP_DELAY = 0.2
AUTO_ACKNOLEDGE_DELAY = 24.0

PID_FILE = '/var/run/sark.pid'

logging.basicConfig()
logger = logging.getLogger()
handler = SysLogHandler( address='/dev/log', facility=SysLogHandler.LOG_DAEMON )
handler.setFormatter( logging.Formatter( fmt='sark[%(process)d]: %(message)s' ) )
logger.addHandler( handler )
if '-v' in sys.argv:
  logger.setLevel( logging.DEBUG )
elif '-c' in sys.argv:
  logger.setLevel( logging.ERROR )
else:
  logger.setLevel( logging.INFO )

if os.path.exists( PID_FILE ):
  logging.error( 'pid file exists, bailing...' )
  sys.exit( 0 )

tmp = open( PID_FILE, 'w' )
tmp.write( '{0}\n'.format( os.getpid() ) )
tmp.close()

slack = Slack( 'sark', settings.SLACK_API_TOKEN, settings.SLACK_CHANNEL, settings.SITE_NAME, settings.SLACK_PROXY )


# Iterate over the Queued Items
for item in QueueItem.objects.all().order_by( '-priority' ):  # start with the biggest number first
  try:
    # Check to see if resources are aviable
    ( compute_status, network_status, target_network ) = item.checkResources()
    if compute_status:
      logging.info( 'Queue Item "{0}" waiting for compute "{1}"'.format( item, compute_status ) )
      item.resource_status_map = { 'compute': compute_status }
      item.full_clean()
      item.save()
      continue

    if network_status:
      logging.info( 'Queue Item "{0}" waiting for network "{1}"'.format( item, network_status ) )
      item.resource_status_map = { 'network': network_status }
      item.full_clean()
      item.save()
      continue

  except Exception as e:
    logging.exception( 'Exception "{0}" checking resources for item "{1}", skiping...'.format( e, item.pk ) )
    item.resource_status_map = { 'error': 'Exception: "{0}"'.format( e ) }
    item.full_clean()
    item.save()
    continue

  job = None
  try:
    # Build a job
    job = BuildJob()
    job.manual = item.manual
    job.user = item.user
    job.build = item.build
    job.project = item.project
    job.branch = item.branch
    job.target = item.target
    job.commit = item.commit
    job.promotion = item.promotion
    job.full_clean()
    job.save()

    # allocate the Resources
    item.allocateResources( job, target_network )
    logging.info( 'Starting Queue Item "{0}" as job "{1}"'.format( item, job.id ) )

  except Exception as e:
    logging.exception( 'Exception "{0}" creating job for queue item "{1}", skiping...'.format( e, item.pk ) )

    item.resource_status_map = { 'error': 'Exception: "{0}"'.format( e ) }
    item.full_clean()
    item.save()
    continue

  # remove the queue Item
  slack.post_message( 'Job {0} ( project: "{1}", build: "{2}", branch: "{3}", target: "{4}" ) for Queue Item {5} submitted.'.format( job.id, job.project.name, job.build.name, job.branch, job.target, item.id ), slack.INFO )
  item.delete()


# Iterate over the build new jobs
for job in BuildJob.objects.filter( built_at__isnull=True, ran_at__isnull=True, reported_at__isnull=True, released_at__isnull=True ):
  ready = True
  for instance in job.instance_set.all():
    ready &= instance.state == 'built'

  # all done, set to built
  if ready:
    logging.info( 'Setting job "{0}" to Built.'.format( job.id ) )
    job.built_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()

# the Job will flag it's self as Ran

# Iterate over the Ran jobs, and signalComplete
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=True, released_at__isnull=True ):
  if job.commit is not None:
    job.commit.signalComplete( job.target, job.build.name, job.suceeded )

  elif job.promotion is not None:
    job.promotion.signalComplete( job.build )

  else:
    logging.info( 'Job has nothing to report to, hopfully that was intentional' )

  logging.info( 'Setting job "{0}" to Reported.'.format( job.id ) )
  job.reported_at = datetime.now( timezone.utc )
  job.full_clean()
  job.save()

  results = ''
  for instance in job.instance_set.all().order_by( 'name' ):
    results += 'Instance: *{0}*\n'.format( instance )
    try:
      results += 'Success: *{0}*\n'.format( instance.success )
    except KeyError:
      pass

  slack.post_message( 'Job {0} ( project: "{1}", build: "{2}", branch: "{3}", target: "{4}" ) Completed.\n{5}'.format( job.id, job.project.name, job.build.name, job.branch, job.target, results ), slack.INFO )


# iterate over the Reported jobs that are not manual and look to see if the resources are all released
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, acknowledged_at__isnull=True, released_at__isnull=True, manual=False ):
  if job.suceeded:  # success auto Acknoledges
    job.acknowledged_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()
    continue

  # auto acknoledge after AUTO_ACKNOLEDGE_DELAY
  if job.reported_at < ( datetime.now( timezone.utc ) - timedelta( hours=AUTO_ACKNOLEDGE_DELAY ) ):
    job.acknowledged_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()
    continue


# iterate over the Acknoledged jobs, and release the resources
for job in BuildJob.objects.filter( built_at__isnull=False, ran_at__isnull=False, reported_at__isnull=False, acknowledged_at__isnull=False, released_at__isnull=True ):
  for instance in job.instance_set.all():
    if instance.state == 'built':
      instance.release()

  ready = True
  for instance in job.instance_set.all():
    ready &= instance.state == 'released'

  # resources all released, set job to released
  if ready:
    logging.info( 'Setting job "{0}" to Released.'.format( job.id ) )
    job.released_at = datetime.now( timezone.utc )
    job.full_clean()
    job.save()


# Iterate over released jobs that are at least CLEANUP_DELAY hours old and delete them
for job in BuildJob.objects.filter( released_at__lt=( datetime.now( timezone.utc ) - timedelta( hours=CLEANUP_DELAY ) ) ):
  logging.info( 'Cleaning up job "{0}".'.format( job.id ) )
  for instance in job.instance_set.all():
    instance.delete()

  job.delete()


os.unlink( PID_FILE )
logging.info( 'Done!' )
logging.shutdown()
sys.exit( 0 )
